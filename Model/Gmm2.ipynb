{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fftpack import rfft, irfft, fftfreq, fft, rfftfreq, ifft\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from IPython.display import Audio\n",
    "import python_speech_features as mfcc\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "    rows, cols = array.shape\n",
    "    deltas = np.zeros((rows, 20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i - j < 0:\n",
    "                first = 0\n",
    "            else:\n",
    "                first = i - j\n",
    "            if i + j > rows - 1:\n",
    "                second = rows - 1\n",
    "            else:\n",
    "                second = i + j\n",
    "            index.append((second, first))\n",
    "            j += 1\n",
    "        deltas[i] = (array[index[0][0]] - array[index[0][1]] + (2 * (array[index[1][0]] - array[index[1][1]]))) / 10\n",
    "    return deltas\n",
    "\n",
    "def extract_features(audio, rate):\n",
    "    mfcc_feature = mfcc.mfcc(audio, rate, 0.025, 0.01, 20, nfft=1200, appendEnergy=True)\n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature, delta))\n",
    "    return combined\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "audio , sr = librosa.load(\"D:/My PC/Projects/DSP/Voice-Recognition-System/vrs-server/apis/operating.wav\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-11.00147748, -11.38914763, -10.31283477, ...,   0.02043865,\n         -1.63380095,  -0.24656912],\n       [ -9.81863555,  -5.54769192,  -0.49589006, ...,  -3.49370826,\n          2.04526672,  -1.61276928],\n       [ -9.35784138,  -7.21872803,  -2.75698383, ...,  -3.31973907,\n          2.72262115,  -3.84791742],\n       ...,\n       [-12.37579473,  -0.94456399,  10.89720143, ...,  -1.12773728,\n         -3.63915005,   1.15669907],\n       [-12.06800837,   0.49684137,  14.41798452, ...,  -1.93619499,\n         -5.22528539,   0.63424446],\n       [-12.49570662,   1.08088807,  15.09407071, ...,  -2.49154645,\n         -6.23143037,   0.2544087 ]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_feature = mfcc.mfcc(audio, sr, 0.025, 0.01, 20, nfft=1200, appendEnergy=True)\n",
    "mfcc_feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(270, 20)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = mfcc_feature\n",
    "rows, cols = array.shape\n",
    "rows, cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas = np.zeros((rows, 20))\n",
    "deltas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.44701141,  1.41822949,  2.49286466, ..., -1.01945023,\n         1.23919119, -0.85688968],\n       [ 0.47541117,  3.01647205,  4.74124115, ..., -1.0644896 ,\n         1.30428173, -1.45667853],\n       [ 0.33565721,  2.47164721,  3.55582344, ..., -0.60812563,\n         0.16751348, -1.58502887],\n       ...,\n       [ 0.11282526,  0.4532195 ,  1.33854667, ..., -1.19858737,\n        -0.44187493, -0.44705617],\n       [-0.01326336,  0.62830073,  1.45902544, ..., -0.8631943 ,\n        -0.64964622, -0.53771257],\n       [-0.0667522 ,  0.46349508,  0.90698247, ..., -0.32829698,\n        -0.61907056, -0.21844165]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2\n",
    "for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i - j < 0:\n",
    "                first = 0\n",
    "            else:\n",
    "                first = i - j\n",
    "            if i + j > rows - 1:\n",
    "                second = rows - 1\n",
    "            else:\n",
    "                second = i + j\n",
    "            index.append((second, first))\n",
    "            j += 1\n",
    "        deltas[i] = (array[index[0][0]] - array[index[0][1]] + (2 * (array[index[1][0]] - array[index[1][1]]))) / 10\n",
    "deltas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.5092952 , -0.55806187, -1.06936772, ..., -0.24611208,\n         0.30272876, -0.25283244],\n       [-0.24671817, -0.14795399, -0.15677692, ..., -0.25698532,\n         0.31863008, -0.42980514],\n       [-0.14442727, -0.26527151, -0.36696995, ..., -0.14681154,\n         0.04092278, -0.46767598],\n       ...,\n       [-0.81437752,  0.1752153 ,  0.9023337 , ..., -0.28935873,\n        -0.10794803, -0.13190765],\n       [-0.74605255,  0.27641125,  1.22962843, ..., -0.20838932,\n        -0.15870561, -0.15865657],\n       [-0.84099655,  0.3174151 ,  1.29247792, ..., -0.0792563 ,\n        -0.15123612, -0.06445303]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(audio, sr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def train(csvs):\n",
    "    models = list()\n",
    "    for csv in csvs:\n",
    "        df = pd.read_csv(csv)\n",
    "        X = df.drop(columns='label', axis=1)\n",
    "\n",
    "\n",
    "        cols = X.columns\n",
    "        X = df.drop(columns=[cols[0],'label'], axis=1)\n",
    "        cols = X.columns\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        np_scaled = min_max_scaler.fit_transform(X)\n",
    "        # new data frame with the new scaled data.\n",
    "        X = pd.DataFrame(np_scaled, columns=cols)\n",
    "        gmm = GMM(n_components=8).fit(X)\n",
    "        models.append(gmm)\n",
    "\n",
    "    return models\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def score(models, audio_path):\n",
    "\n",
    "    audio, sr = librosa.load(audio_path, duration=2)\n",
    "    audio = librosa.effects.trim(audio)\n",
    "    audio = audio[0]\n",
    "\n",
    "    features = [librosa.feature.chroma_stft(y=audio, sr=sr).mean(), librosa.feature.chroma_stft(y=audio, sr=sr).var(),\n",
    "                librosa.feature.rms(y=audio).mean(), librosa.feature.rms(y=audio).var(),\n",
    "                librosa.feature.spectral_centroid(y=audio).mean(),librosa.feature.spectral_centroid(y=audio).var(),\n",
    "                librosa.feature.spectral_bandwidth(y=audio).mean(),librosa.feature.spectral_bandwidth(y=audio).var(),\n",
    "                librosa.feature.spectral_rolloff(y=audio).mean(),librosa.feature.spectral_rolloff(y=audio).var()]\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=audio)\n",
    "    mfcc_list = []\n",
    "    for i in range(len(mfcc)):\n",
    "         mfcc_list.append(mfcc[i].mean())\n",
    "\n",
    "\n",
    "    features = features + mfcc_list\n",
    "    score_list = np.zeros(len(models))\n",
    "    for i in range(len(models)):\n",
    "        out = np.array(models[i].score([features]))\n",
    "        score_list[i] = out.sum()\n",
    "\n",
    "        # score_list.append(model.score([features]))\n",
    "    return score_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.61565422e+18 -4.31904848e+18 -3.77256385e+18 -4.28236374e+18]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I1bra\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GaussianMixture was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\I1bra\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GaussianMixture was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\I1bra\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GaussianMixture was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\I1bra\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GaussianMixture was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "csvs = ['Mariam.csv','Amr.csv','Momen.csv','ibrahim.csv']\n",
    "models = train(csvs)\n",
    "myScoreList = score(models, 'D:/My PC/Projects/DSP/Voice-Recognition-System/Model/Website Data/Ibrahim/10.wav')\n",
    "print(myScoreList)\n",
    "winner = np.argmax(myScoreList)\n",
    "print(winner)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}